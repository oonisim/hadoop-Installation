#--------------------------------------------------------------------------------
# Remove the conversion result data.
#--------------------------------------------------------------------------------
- name: "Clean {{ _APP_HDFS_IN_DIR }}/DigitalBreathTestData2013.csv in HDFS"
  become: true
  become_user: "{{ HADOOP_ADMIN }}"
  shell: | 
    hdfs dfs -rm -r -f {{ _APP_HDFS_IN_DIR }}/DigitalBreathTestData2013.csv
  environment: 
    PATH: "{{ ansible_env.PATH }}:{{ HADOOP_HOME }}/bin:{{ SPARK_HOME }}:/bin"
    JAVA_HOME: "{{ java_home.stdout }}"    
  ignore_errors: true

#--------------------------------------------------------------------------------
# To run Spark with YARN, DO NOT forget to provide HADOOP_CONF_DIR environment
# at Ansible level as become/sudo will strip away enviornment variables.
#--------------------------------------------------------------------------------
- name: "Run convert"
  become: true
  become_user: "{{ SPARK_ADMIN }}"
  shell: |
    {{ SPARK_HOME }}/bin/spark-submit \
    --class convert1 \
    --master {{ SPARK_MASTER }} \
    --deploy-mode {{ SPARK_DEPLOY_MODE }} \
    --executor-memory 700M \
    {{ _APP_BUILD_DIR }}/target/scala-2.11/naive-bayes_2.11-1.0.jar
  environment:
#    PATH: "{{ ansible_env.PATH }}:{{ HADOOP_HOME }}/bin:{{ SPARK_HOME }}:/bin"
    JAVA_HOME: "{{ java_home.stdout }}"
    HADOOP_CONF_DIR: "{{ HADOOP_CONF_DIR }}"

- name: "Run bayes"
  become: true
  become_user: "{{ SPARK_ADMIN }}"
  shell: |
    {{ SPARK_HOME }}/bin/spark-submit \
    --class bayes1 \
    --master {{ SPARK_MASTER }} \
    --deploy-mode {{ SPARK_DEPLOY_MODE }} \
    --executor-memory 700M \
    {{ _APP_BUILD_DIR }}/target/scala-2.11/naive-bayes_2.11-1.0.jar
  environment:
#    PATH: "{{ ansible_env.PATH }}:{{ HADOOP_HOME }}/bin:{{ SPARK_HOME }}:/bin"
    JAVA_HOME: "{{ java_home.stdout }}"    
    HADOOP_CONF_DIR: "{{ HADOOP_CONF_DIR }}"
